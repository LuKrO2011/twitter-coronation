{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter downloader\n",
    "This notebook downloads tweets from Twitter. A search query and date has to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import twitterClient\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(filename):\n",
    "    \"\"\"\n",
    "    Loads the tweets from the file with the given name into an array of tweets.\n",
    "\n",
    "    @param filename: The filename of the file to load the tweets from.\n",
    "\n",
    "    @returns: An array of tweets.\n",
    "    \"\"\"\n",
    "    tweets = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for sLine in f:\n",
    "            tweet = json.loads(sLine)\n",
    "            tweets.append(tweet)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = twitterClient.twitterClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what tweets do download\n",
    "search_query = 'coronation (kingcharles OR charles)'\n",
    "\n",
    "end_time = parser.parse(\"05.05.2023 23:59\")\n",
    "\n",
    "# All non-authenticated tweet fields\n",
    "all_tweet_fields = ['id', 'text', 'attachments', 'author_id', 'context_annotations', 'conversation_id', 'created_at', 'entities', 'geo', 'in_reply_to_user_id', 'lang', 'possibly_sensitive', 'public_metrics', 'referenced_tweets', 'reply_settings', 'source', 'withheld']\n",
    "\n",
    "# The maximum amount of tweets to download\n",
    "max_tweets = 100000  # 50000 was used here\n",
    "\n",
    "# The filename of the file to store the tweets into\n",
    "all_twitter_fields_filename = \"../data/coronation_2023_05_05_3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "twitterResponse = client.search_recent_tweets(search_query, max_results=100, tweet_fields=all_tweet_fields, end_time=end_time) # User next_token=\"...\" to continue downloading\n",
    "while len(tweets) < max_tweets:\n",
    "    try:\n",
    "        twitterResponse = client.search_recent_tweets(search_query, max_results=100, tweet_fields=all_tweet_fields, next_token=twitterResponse.meta.get(\"next_token\"), end_time=end_time)\n",
    "    except:\n",
    "        break\n",
    "    finally:\n",
    "        print(len(tweets))\n",
    "\n",
    "    if twitterResponse.data is not None:\n",
    "        for tweet in twitterResponse.data:\n",
    "            tweets.append(tweet)\n",
    "\n",
    "print(\"Number of tweets downloaded: \", len(tweets))\n",
    "print(twitterResponse.meta.get(\"next_token\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(all_twitter_fields_filename, 'w') as json_file:\n",
    "    for tweet in tweets:\n",
    "        json.dump(tweet.data, json_file)\n",
    "        json_file.write('\\n')\n",
    "\n",
    "print(\"Tweets successfully stored to: \", all_twitter_fields_filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
